# ðŸ©º Medical Voice Chatbot MVP (RAG + Ollama + Streamlit)

This project is an MVP (Minimum Viable Product) for a **privacy-focused, voice-enabled medical chatbot**. It leverages a **Retrieval-Augmented Generation (RAG)** pipeline using **Mistral 7B via Ollama**, **ChromaDB** for vector storage, and **Streamlit** as the frontend interface.  
Voice input is supported, and the architecture is designed to easily extend to include **Digital Twin**, **caching**, and **account management** in future releases.

---

## ðŸš€ Features

- ðŸ” **RAG Pipeline**: Answers based on a local medical knowledge base (PDF or text)
- ðŸ§  **LLM**: `mistral:7b` running via Ollama
- ðŸŽ¤ **Voice Input**: Query the chatbot using your microphone
- ðŸ§¾ **ChromaDB**: Local vector store for embeddings
- ðŸŒ **Streamlit UI**: Clean, browser-based frontend
- ðŸ§¬ **Digital Twin (Planned)**: Placeholder in code for virtual patient personalization

---

## ðŸ“ Project Structure

medical_chatbot_mvp/
â”‚
â”œâ”€â”€ dataIngestion/
â”‚ â”œâ”€â”€ embedding.py # Embedding logic using Sentence Transformers
â”‚ â”œâ”€â”€ extraction.py # Document loading and text extraction
â”‚ â””â”€â”€ utils.py # Helper functions for ingestion
â”‚
â”œâ”€â”€ QASystem/
â”‚ â”œâ”€â”€ prompts.py # Prompt template for Ollama
â”‚ â”œâ”€â”€ tts.py # Optional text-to-speech (output audio)
â”‚ â”œâ”€â”€ voice.py # Speech-to-text handling
â”‚ â”œâ”€â”€ output.py # Text/audio output formatting
â”‚ â””â”€â”€ utils.py # LLM and query engine wrapper
â”‚
â”œâ”€â”€ raw_docs/ # Folder for medical PDFs and documents
â”‚
â”œâ”€â”€ tests/ # Unit and integration test cases
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ exception.py # Custom error handling
â”‚ â””â”€â”€ logger.py # Project logging setup
â”‚
â”œâ”€â”€ ingestion.py # Script to ingest and index documents
â”œâ”€â”€ main.py # Entry point for Streamlit chatbot app
â”œâ”€â”€ setup.py # Optional project packaging
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ðŸ”§ Requirements

- Python `>= 3.10.12`
- RAM: `>= 16GB`
- Ollama installed with `mistral:7b` pulled locally
- ChromaDB
- Streamlit

---

## ðŸ“¦ Installation

```bash
# 1. Clone the repo
git clone [https://github.com/yourusername/medical-chatbot-mvp.git](https://github.com/kalalsahil/Medical_bot.git)
cd medical_chatbot_mvp

# 2. Set up virtual environment
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt
python setup.py install
OR
pip install -e .

# 4. Start Ollama and pull Mistral model
ollama pull mistral

# 5. Ingest data
python ingestion.py

# 6. Test
pytest tests/

# 7. Run the chatbot
streamlit run main.py
