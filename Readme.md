# ğŸ©º Medical Voice Chatbot MVP (RAG + Ollama + Streamlit)

This project is an MVP (Minimum Viable Product) for a **privacy-focused, voice-enabled medical chatbot**. It leverages a **Retrieval-Augmented Generation (RAG)** pipeline using **Mistral 7B via Ollama**, **ChromaDB** for vector storage, and **Streamlit** as the frontend interface.  
Voice input is supported, and the architecture is designed to easily extend to include **Digital Twin**, **caching**, and **account management** in future releases.

---

## ğŸš€ Features

- ğŸ” **RAG Pipeline**: Answers based on a local medical knowledge base (PDF or text)
- ğŸ§  **LLM**: `mistral:7b` running via Ollama
- ğŸ¤ **Voice Input**: Query the chatbot using your microphone
- ğŸ§¾ **ChromaDB**: Local vector store for embeddings
- ğŸŒ **Streamlit UI**: Clean, browser-based frontend
- ğŸ§¬ **Digital Twin (Planned)**: Placeholder in code for virtual patient personalization

---

## ğŸ“ Project Structure

medical_chatbot_mvp/<br>
â”‚<br>
â”œâ”€â”€ dataIngestion/<br>
â”‚ â”œâ”€â”€ embedding.py # Embedding logic using Sentence Transformers<br>
â”‚ â”œâ”€â”€ extraction.py # Document loading and text extraction<br>
â”‚ â””â”€â”€ utils.py # Helper functions for ingestion<br>
â”‚<br>
â”œâ”€â”€ QASystem/<br>
â”‚ â”œâ”€â”€ prompts.py # Prompt template for Ollama<br>
â”‚ â”œâ”€â”€ tts.py # Optional text-to-speech (output audio)<br>
â”‚ â”œâ”€â”€ voice.py # Speech-to-text handling<br>
â”‚ â”œâ”€â”€ output.py # Text/audio output formatting<br>
â”‚ â””â”€â”€ utils.py # LLM and query engine wrapper<br>
â”‚<br>
â”œâ”€â”€ raw_docs/ # Folder for medical PDFs and documents<br>
â”‚<br>
â”œâ”€â”€ tests/ # Unit and integration test cases<br>
â”‚<br>
â”œâ”€â”€ utils/<br>
â”‚ â”œâ”€â”€ exception.py # Custom error handling<br>
â”‚ â””â”€â”€ logger.py # Project logging setup<br>
â”‚<br>
â”œâ”€â”€ ingestion.py # Script to ingest and index documents<br>
â”œâ”€â”€ main.py # Entry point for Streamlit chatbot app<br>
â”œâ”€â”€ setup.py # Optional project packaging<br>
â”œâ”€â”€ requirements.txt<br>
â””â”€â”€ README.md

---

## ğŸ”§ Requirements

- Python `>= 3.10.12`
- RAM: `>= 16GB`
- Ollama installed with `mistral:7b` pulled locally
- ChromaDB
- Streamlit

---

## ğŸ“¦ Installation

```bash
# 1. Clone the repo
git clone [https://github.com/yourusername/medical-chatbot-mvp.git](https://github.com/kalalsahil/Medical_bot.git)
cd medical_chatbot_mvp

# 2. Set up virtual environment
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt
python setup.py install
OR
pip install -e .

# 4. Start Ollama and pull Mistral model
ollama pull mistral

# 5. Ingest data
python ingestion.py

# 6. Test
pytest tests/

# 7. Run the chatbot
streamlit run main.py
